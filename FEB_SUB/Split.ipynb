{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c808bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f807e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_File = Path('Data/Obs_df.csv')\n",
    "\n",
    "if SRC_File.exists():\n",
    "\tdf_whole = pd.read_csv(SRC_File)\n",
    "else:\n",
    "\traise FileNotFoundError(f\"The file {SRC_File} does not exist. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45689031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(SRC_File, low_memory=False)\n",
    "\n",
    "def coalesce(a, b):\n",
    "    \"\"\"Prefer a; if blank/NA use b.\"\"\"\n",
    "    a = a.fillna(\"\").astype(str).str.strip().replace({\"\": np.nan})\n",
    "    b = b.fillna(\"\").astype(str).str.strip().replace({\"\": np.nan})\n",
    "    return a.combine_first(b)\n",
    "\n",
    "def clean_text(s):\n",
    "    \"\"\"Trim whitespace; turn '', 'nan', 'None' into NA; keep original case.\"\"\"\n",
    "    s = s.astype(str).str.strip()\n",
    "    s = s.replace({\"\": np.nan, \"nan\": np.nan, \"None\": np.nan, \"NONE\": np.nan})\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53af6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesced scientific names per side\n",
    "pred_sci = coalesce(df.get(\"predator_scientific_name\"), df.get(\"predator_taxon_species_name\"))\n",
    "prey_sci = coalesce(df.get(\"prey_scientific_name\"), df.get(\"prey_taxon_species_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f6fefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble candidate taxa rows from predator side\n",
    "pred_taxa = pd.DataFrame({\n",
    "    \"scientific_name\": pred_sci,\n",
    "    \"common_name\": df.get(\"predator_common_name\"),\n",
    "    \"iconic_taxon_name\": df.get(\"predator_iconic_taxon_name\"),\n",
    "    \"taxon_kingdom\": df.get(\"predator_taxon_kingdom_name\"),\n",
    "    \"taxon_id\": df.get(\"predator_taxon_id\"),\n",
    "})\n",
    "\n",
    "# â€¦and prey side\n",
    "prey_taxa = pd.DataFrame({\n",
    "    \"scientific_name\": prey_sci,\n",
    "    \"common_name\": df.get(\"prey_common_name\"),\n",
    "    \"iconic_taxon_name\": df.get(\"prey_iconic_taxon_name\"),\n",
    "    \"taxon_kingdom\": df.get(\"prey_taxon_kingdom_name\"),\n",
    "    \"taxon_id\": df.get(\"prey_taxon_id\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "622ec295",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa = pd.concat([pred_taxa, prey_taxa], ignore_index=True)\n",
    "taxa[\"scientific_name\"] = clean_text(taxa[\"scientific_name\"])\n",
    "taxa = taxa.dropna(subset=[\"scientific_name\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0838261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         scientific_name                 common_name iconic_taxon_name  \\\n",
       " 0      Abantis paradisea            Paradise Skipper           Insecta   \n",
       " 1  Abisares viridipennis  Notched Shield Grasshopper           Insecta   \n",
       " 2          Abramis brama                Common Bream    Actinopterygii   \n",
       " 3       Abrus laevigatus                  Lucky Bean           Plantae   \n",
       " 4        Acalitus mallyi       Mispel Leaf Gall Mite         Arachnida   \n",
       " \n",
       "   taxon_kingdom  taxon_id  \n",
       " 0      Animalia       NaN  \n",
       " 1      Animalia       NaN  \n",
       " 2      Animalia       NaN  \n",
       " 3       Plantae       NaN  \n",
       " 4      Animalia       NaN  ,\n",
       " (1876, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_nonnull(series):\n",
    "    return series.dropna().iloc[0] if series.notna().any() else np.nan\n",
    "\n",
    "taxa = (taxa\n",
    "        .sort_values(\"scientific_name\")\n",
    "        .groupby(\"scientific_name\", as_index=False)\n",
    "        .agg({\n",
    "            \"common_name\": first_nonnull,\n",
    "            \"iconic_taxon_name\": first_nonnull,\n",
    "            \"taxon_kingdom\": first_nonnull,\n",
    "            \"taxon_id\": first_nonnull\n",
    "        }))\n",
    "\n",
    "taxa.head(), taxa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c684f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = pd.DataFrame({\n",
    "    \"uuid\": df.get(\"uuid\"),\n",
    "    \"predator_scientific_name\": pred_sci,\n",
    "    \"prey_scientific_name\": prey_sci,\n",
    "    \"observed_on\": df.get(\"observed_on\"),\n",
    "    \"time_observed_at\": df.get(\"time_observed_at\"),\n",
    "    \"place\": df.get(\"place_guess\"),\n",
    "    \"place_town\": df.get(\"place_town_name\"),\n",
    "    \"place_county\": df.get(\"place_county_name\"),\n",
    "    \"place_state\": df.get(\"place_state_name\"),\n",
    "    \"place_country\": df.get(\"place_country_name\"),\n",
    "    \"latitude\": df.get(\"latitude\"),\n",
    "    \"longitude\": df.get(\"longitude\"),\n",
    "    \"special_feeding\": df.get(\"special_type_of_feeding\"),\n",
    "    \"url\": df.get(\"url\"),\n",
    "    \"image_url\": df.get(\"image_url\"),\n",
    "    \"predator_quality\": df.get(\"predator_quality_grade\"),\n",
    "    \"prey_quality\": df.get(\"prey_quality_grade\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f46c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean endpoints\n",
    "rels[\"predator_scientific_name\"] = clean_text(rels[\"predator_scientific_name\"])\n",
    "rels[\"prey_scientific_name\"] = clean_text(rels[\"prey_scientific_name\"])\n",
    "\n",
    "# Drop rows missing either endpoint\n",
    "rels = rels.dropna(subset=[\"predator_scientific_name\", \"prey_scientific_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4e8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numeric types (non-numeric coerced to NaN)\n",
    "rels[\"latitude\"] = pd.to_numeric(rels[\"latitude\"], errors=\"coerce\")\n",
    "rels[\"longitude\"] = pd.to_numeric(rels[\"longitude\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b013d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ensure every relationship endpoint exists in taxa\n",
    "pred_missing = set(rels[\"predator_scientific_name\"]) - set(taxa[\"scientific_name\"])\n",
    "prey_missing = set(rels[\"prey_scientific_name\"]) - set(taxa[\"scientific_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82ff375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predators missing in taxa: 0\n",
      "Prey missing in taxa: 0\n",
      "Taxa rows: 1876\n",
      "EATS rows: 3938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Predators missing in taxa:\", len(pred_missing))\n",
    "print(\"Prey missing in taxa:\", len(prey_missing))\n",
    "\n",
    "# 2) Basic sanity counts\n",
    "print(\"Taxa rows:\", len(taxa))\n",
    "print(\"EATS rows:\", len(rels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51b459a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate scientific names: 0\n"
     ]
    }
   ],
   "source": [
    "# 3) Check for obvious duplication in scientific names (post-normalization)\n",
    "dup_names = taxa[\"scientific_name\"].value_counts()\n",
    "dup_names = dup_names[dup_names > 1]\n",
    "print(\"Duplicate scientific names:\", len(dup_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da9fa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa.to_csv(\"taxa.csv\", index=False)\n",
    "rels.to_csv(\"eats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8529ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
